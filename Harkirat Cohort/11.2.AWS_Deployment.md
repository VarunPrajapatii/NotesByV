# AWS Deployment

AWS (Amazon Web Services) is Amazon's cloud platform, which provides various services like renting servers, managing domains, uploading objects, autoscaling, and creating Kubernetes (K8s) clusters. Understanding how to deploy applications on AWS is an essential skill for software development engineers (SDEs), especially when working on scalable, distributed systems.s

### Why Can’t the World Access My Code from My Local Machine?

When you're connected to the internet at home, you're still behind a private IP. Public IPs are limited, and most devices are behind NAT (Network Address Translation), which assigns private IPs. The internet relies on public IPs, but not every machine on the internet has a public IP address. Cloud providers like AWS give virtual machines (VMs) a public IP address, making them accessible from anywhere in the world.

### Virtual Machines on AWS (EC2)
AWS's virtual machines are called EC2 (Elastic Compute Cloud) instances. EC2 allows you to rent virtual machines with elastic scalability, meaning you can increase or decrease the resources as needed.

Key Points:
- **Elastic**: You can scale the machine up or down based on load.
- **Compute**: It’s essentially a virtual server that performs computations.

#### Creating a New EC2 Server
To create a new EC2 instance:
1. Go to the AWS Management Console and select **Launch a new instance**.
2. Name your instance.
3. Choose an **Operating System** (Ubuntu is common for most Node.js applications).
4. Select **Instance Type** (size based on your application requirements).
5. Create a **Key Pair** (this is required for secure SSH access).
6. Set **Security Group** to allow traffic on HTTP (port 80), HTTPS (port 443), and SSH (port 22).
7. Launch the instance.

>Understand the importance of securing your key pair and configuring inbound rules to avoid exposing services unnecessarily.
>

To AWS you want to tell up upfront, eg. theres something running on the port lets say 3000, and should this port be open to the internet. AWS asks what port it should make accessible to the internet.
### SSH Access to the Server
There is a option "Allow SSH traffic from anywhere". SSH stands for Secure Shell, securely connecting to the shell is the meaning of ssh to the machine, So to access that VM from our pc we have to open the ssh port on this machine, which by default is 22.
To securely access the EC2 instance, you’ll use SSH (Secure Shell). You will need to provide a private key (generated during the EC2 setup) to connect to your server.
Then we allow http (port 80) and https (port 443) traffic from anywhere. If not this lets say we are running our app on port 3000 then people have to mention like www.varun.com:3000 which is not a good way.
Now our instance is live, its charging us, now lets deploy our backend application. Now lets connect/ssh to the server.

#### Common Error: "Unprotected Private Key"
In your terminal go to the specific folder where the ssh key is present.
Remember this command to ssh to the VM - `ssh -i pem_file_name os_of_machine@ip_of_machine`
There comes a error - "WARNING: UNPROTECTED PRIVATE KEY FILE!"
Then try to run: `chmod 700 pem_fime_name` then we ran the ssh command and we would successfully be able to connect to the machine. 
- **These all we are doing is for MacOS command line.**
- **On windows we can use putty.** its a gui that lets us do same thing.
The error comes if the certificate file is too open, by which we mean if it has too much permissions like it can be accessed by any user of your pc, then you get the warning. Thats why we run this command which makes the file restrictive.


### SSH into the server
1. Give ssh key permissions<br/>
`chmod 700 kirat-class.pem`

2. ssh into machine<br/>
`ssh -i kirat-class.pem ubuntu@ec2-65-0-180-32.ap-south-1.compute.amazonaws.com`

3. Clone repo<br/>
`git clone (link)`

- If your aws machine shows "Temporary failure in name resolution" you the following error, your aws machine doesn’t have access to the internet. Edit the DNS configuration in `/etc/resolv.conf` to include: `nameserver 8.8.8.8`

So our aws server cant be able to hit a dns server, which converts the domain name to ip, so it doesnt understand the name github.
For that you open the file `/etc/resolv.conf`

So you have to open the file and make changes-
    - `sudo vi /etc/resolv.conf`  (sudo means super user do)
    - we open this file and add this entry over there (nameserver 8.8.8.8)
    - we open this file with vi or nano which are terminal based editors.
    - go to the file, press i to go to insert mode, then go to the line then paste the nameserver 8.8.8.8
    - then esc and do `:wq` and press enter and this change the file.
    - Now you go type "ping google.com" and you can actually hit the google.com


>Solution - https://www.tecmint.com/resolve-temporary-failure-in-name-resolution/
>

Then we clone the repo. `git clone <repo-link>`. The you ls in the VM and you should see the repo.

4. Install Node.js:
    - You can try using nvm (node version manager) to install node.js in your VM. Using this command:
    - `curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.3/install.sh | bash`
    - Alternatively, use the Ubuntu package manager or follow DigitalOcean tutorials. https://www.digitalocean.com/community/tutorials/how-to-install-node-js-on-ubuntu-20-04
    - It will install nvm and it will give you something which you copy and run then you type nvm on terminal you will see that nvm is there in the VM.
    - Then we do `nvm install 20` or whatever version of node you want to install.
    - Then try to run npm, it should work.

>So whenever you buy a machine you have to install node in it and actually run it, thats what we are doing now. But ideally you shouldnt do it. Ideally you should containerize your application, that way your machine doesnt need nodejs only your docker container does. What we're doing now is the most raw/beginner friendly way to do the deployement.
>

5. Install all dependencies
    `cd (folder name)` <br/>
    `npm install`
6. Start backend
    `node index.js`

And now a backend application is running on a server.

### Try hitting the Server
- You have an ip/DNS that you can hit to access your ec2 server.
- In your express app lets say you wrote app.listen(8080)
- You will be opening your website hosted like http://your_domain:8080, you have to write :8080 everytime.
- Now you wont be able to hit it as the security group says that 443, 80, 22 is open.
- So go to the aws ec2 and in the Security Groups select the security group and Make a custom TCP with 8080, and you can hit this http://your_domain:8080.
- If it was on port 80 then you dont have to mention it, you can hit the domain name with http, or if it was on port 443 you didnt need to mention the port, you can directly hit the domain name with https.

- See one thing, you can see ways and can do app.listen(80) or 443 and when hitting url you need not to write :port in the url link. You shouldnt do it. Your nodejs process should never listen on port 80 or 443. 


### Reverse Proxy
Now lets say you were able to run it on port to 80 some how, now you need not to mention the port number, now lets say you have to deploy another backend here, you cannot have two process on port 80.
On the ip/machine you bought, you want be1.varun.com and be2.varun.com both to run, but you cant run both to port 80. You cannot run two processes on the same port, which is why it make sense to use Reverse Proxy. So be1 running on 3000 and be2 running on 3001, so we use reverse proxy here.
We have ec2 machine we're running something else on port 80, a reverse proxy, and it takes care that if incoming url is be1 then it send req to 3000, and if incoming url is be2 then it sends the request to 3001. **The reverse proxy decide what req to send to which port.**
We can start multiple nodejs processes each running on different ports and the req coming to the port 80/nginx will go on different processes based on some constraints, i.e. what url its pointing to.

**Proxy:** so lets say your college has blocked access to badweb.com and you go to chrome and you write a proxy url there, i.e. you add a proxy url there and your req is not going to the badweb.com, rather it goes to the proxy server which is not blocked by your college and then that server sends the req to the blocked url. VPNs are also proxy. So your req is not going to the badweb.com, your website is been proxied by some third server to badweb.com. So youre able to hit the badweb.com through the proxy. Instead of your request going directly to badweb.com, it first goes to the proxy server. The proxy server then forwards your request to badweb.com on your behalf. The proxy server receives the response from badweb.com. It then sends that response back to you. This way, your browser displays the content of badweb.com, but the request never went directly to that site. Since your college has blocked badweb.com, the proxy server acts as a middleman, allowing you to bypass that restriction. A Virtual Private Network (VPN) can be seen as a type of proxy. It not only routes your web traffic through a server but also encrypts it, providing privacy and security while bypassing geographical or network restrictions.
#### Why Use a Reverse Proxy?
- A single machine can’t have multiple services running on the same port (e.g., port 80).
- A reverse proxy like NGINX routes traffic from port 80 to different internal ports based on the URL:
  - Example:  
    - `be1.varun.com` → Port 3000  
    - `be2.varun.com` → Port 3001  

Similar to how a VPN routes your request through a proxy server to bypass restrictions.

## nginx
NGINX is open source software for web serving, reverse proxying, cachiing, load balancing, media streaming, and more. It can also function as a proxy server for email and reverse proxy and load balancer for HTTP, TCP and UDP servers.

1. **Install NGINX:**
```bash
    sudo apt update
    sudo apt install nginx
```
- This will install nginx in your aws machine.
- Try visiting the website. You will see nginx.
- Then go to the google domain, if youve bought the domain from any domain name provider company. Then take the ip of the aws machine and link the be1.varun.com and be2.varun.com to the same ip in google domains. Then when you try to hit these websites you will be able to hit the same end point.

2. **Create reverse proxy - Edit NGINX Configurations**, Delete the default configuration:
`sudo rm /etc/nginx/nginx.conf`<br/>
then reopen the file(Create new configurations):
`sudo vi /etc/nginx/nginx.conf`<br/>
and then paste this content there

```bash
    events {
        # Event directives...
    }

    http {
        server {
            listen 80;
            server_name be1.100xdevs.com;

            location / {
                proxy_pass http://localhost:8080;
                proxy_http_version 1.1;
                proxy_set_header Upgrade $http_upgrade;
                proxy_set_header Connection 'upgrade';
                proxy_set_header Host $host;
                proxy_cache_bypass $http_upgrade;
            }
        }
    }
```

3. **Start NGINX**
```bash
sudo systemctl restart nginx
```

4. **Start the backend server**
```bash
"node index.js"
```

5. **Visit the website**


### Advanced Considerations
- **Security Best Practices**:
  - Use IAM roles and restrict key permissions.
  - Always enable SSL/TLS for secure communication.
- **Performance Optimization**:
  - Use CDNs like CloudFront.
  - Enable caching for frequently accessed content.
- **Scalability**:
  - Use Auto Scaling Groups and Elastic Load Balancers.
  - Opt for containerized deployment using ECS/EKS.

---

### Be familiar with:
- EC2 instance setup and management.
- Reverse proxy and load balancer configurations.
- Debugging deployment issues.


**FAQs:**
- How to deploy frontends and how to tie fe with backend in aws?
    - Deploying frontends is depends on what kind of frontend you are deploying, if its react you deploy usually on CDN, if youre deploying nextjs app, you deploy it ideally on edge servers. If you want to deploy on the EC2 server its as simple as cloning the next repo and running npm run start. And here we doploying be to the ec2 server and in that we got a backend url, you go to the backend and make that url to this, its as simple as that.
    AWS offers a comprehensive suite of services, market leadership, and scalability options.
        - **Reverse Proxy vs. Load Balancer?**
            - **Reverse Proxy**: Routes traffic to multiple applications on a single machine.
            - **Load Balancer**: Distributes traffic across multiple servers for redundancy.

- Why to use aws when we are using cloudflare workers?
    - In aws, youre getting a server, its not serverless. As your app scales, then you probably want to own your servers. Eventually you want to own you infrastructre.

- When i hit google.com it reaches to the diff server and if you hit google.com it reaches to a different server?
    - There is something called anycast ip, so that ip is not a server its just a load balancer, so all the traffic go to the load balancer and it directs the user accordingly.

- If i purchase varun.com how to map the domain name to two different apps like pojects.varun.com connect.varun.com
    - So we can purchase varun.com domain from some place and then in google domain we can link the subdomains to the ip.

- Load Balancers vs Reverse Proxy?
    - Reverse Proxy usually works on the same machine but the load balancers balance accross multiple machines.

