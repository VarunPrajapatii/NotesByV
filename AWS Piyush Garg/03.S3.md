# S3 - Scalable Storge in the Cloud
Simple Storage Service
In this we have buckets to isolate/separate out data, in which we have objects (folder, video, images etc.). With an aws account we can make 100 buckets and in one bucket we can have unlimited data/objects.
So lets create a bucket. You can add objects lets say we add an image in the buvket. By default the public access of object is blocked. Now If we try to access it using the link then we wont be able to access. Although if we make the access public then too we wont be able to access the object. To access we have to add bucket policy to allow read public access to this bucket.
In policy we put Action to getObject and resource to this bucket name, eg. "arn:aws:s3:::varuntd-pencraft/*" 

In AWS, everything is an API call.

In a private bucket, noone can add/access any object. So after making a private bucket if we upload any static file(through console), we will be able to upload, thats called pre-signed URL.
So if you try to access it using the given url, its access denied error. But if you click on the open button on the console, then it will open. See the URL there is a amazon security token there.
We make temp token using which we can access the object. We'll need a signature and token.
To make the access token and signature, the person if IAM user with access to s3, can make these else root user can obviously make the signature and token.
So we make the IAM user and give that user the s3 permissions, so using this user's keys we can access that private bucket objects.
Pre signed URL are for put object or for get object.

## Getting Object

Now make a backend project and install aws sdk library in the project and a library for presigned url, something like @aws-sdk/s3-request-presigner.
Now we write like this
```js
import { S3Client } from "@aws-sdk/client-s3"

const s3Client = new S3Client({
    region: "ap-south-1",
    credentials: {
        accessKeyId: "",
        secretAccessKey: "",
    }
})

async function getObjectURL(key) {
    const command = new GetObjectCommand({
        Bucket: "varun-private",
        Key: key,
    });
    const url = await getSignedUrl(s3Client, command, { expiresIn: 20 });
    return url;
}
```

Now we can make an IAM user and get these keys from that user.

## Putting Object
Lets say we make a project, in which user uploads a video. Now we can store the video in the server memory, but its bad. If many users uploads the video and memory over, then the server crashes. Now we can upload the video on the server and then send it to the s3 bucket. That too is a bad approach as until the video gets fully uploaded to the server and transferred to bucket, the server has to bear the load. So we need to directly upload the object to the s3 directly.
But the problem is we are direct accessing our bucket from frontend, eventually exposing keys of AWS.
To tackle this problem, we have put objects presigned urls. User selects the video and frontend sends the video metadata to the backend and the backend will send the signed url with location as the bucket location where we want to put the video and type will be mp4, valid for lets say 1min.

```js
async function putObject(filename, contentType) {
    const command = new PutObjectCommand({
        Bucket: "varun-proivate",
        Key: `/uploads/user-uploads/${filename}`,
        ContentType: contentType,
    });
    const url = await getSignedUrl(s3Client, command);
    return url;
}
```
contentType eg: "image/jpeg"

now we call the putObject and we get the url. Now go to postman and send a put request with body as binary and select file and send. Now call the getObject and you get a url. Opening which you can find that video.


### List objects command
Lets say we want to list all the objects.

```js
async function listObjects() {
    const command = new ListObjectsV2Command({
        Bucket: "varun-private",
        Key: "/",
    });
    const result = await s3Client.send(command);
    console.log(result);
}
```

Similarly we can do many things, like delete and more...



Lets see more on S3
**Bucket Versioning**: So when you have a video, you overrides it with other video, which eventually increase the cost.

### AWS CloudTrail data events
Like employee working in office does have a log of what he's doing, similarly CloudTrail has track of what IAM user is doing what, it has the logs.

### Event notifications
Whenever lets say a event like put or delete or whatever we chose, triggers, then a lambda function we select will be executed.